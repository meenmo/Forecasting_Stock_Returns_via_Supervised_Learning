{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.ensemble import (\n",
    "BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_series(symbol, start_date, end_date, lags=3):\n",
    "    \n",
    "    ts = web.DataReader(symbol, \"yahoo\", start_date, end_date)\n",
    "    \n",
    "    # Create the new lagged DataFrame\n",
    "    tslag = pd.DataFrame(index=ts.index)\n",
    "    tslag[\"Today\"] = ts[\"Adj Close\"]\n",
    "    tslag[\"Volume\"] = ts[\"Volume\"]\n",
    "    \n",
    "    # Create the shifted lag series of\n",
    "    # prior trading period close values\n",
    "    for i in range(0,lags):\n",
    "        tslag[\"Lag%s\" % str(i+1)] = ts[\"Adj Close\"].shift(i+1)\n",
    "        \n",
    "    # Create the returns DataFrame\n",
    "    tsret = pd.DataFrame(index=tslag.index)\n",
    "    tsret[\"Volume\"] = tslag[\"Volume\"]\n",
    "    tsret[\"Today\"] = tslag[\"Today\"].pct_change()*100.0\n",
    "    \n",
    "    # Create the lagged percentage returns columns\n",
    "    for i in range(0,lags):\n",
    "        tsret[\"Lag%s\" % str(i+1)] = tslag[\"Lag%s\" % str(i+1)].pct_change()*100.0\n",
    "    tsret = tsret[tsret.index >= start_date]\n",
    "    return tsret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2b3d6707d919>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamzn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Today\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Use the training-testing split with 70% of data in the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meenm\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mscale\u001b[1;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[0;32m    143\u001b[0m     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,\n\u001b[0;32m    144\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'the scale function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                     dtype=FLOAT_DTYPES, force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meenm\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     if (warn_on_dtype and dtypes_orig is not None and\n\u001b[1;32m--> 596\u001b[1;33m             {array.dtype} != set(dtypes_orig)):\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;31m# if there was at the beginning some other types than the final one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# (for instance in a DataFrame that can contain several dtypes) then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set the random seed, number of estimators\n",
    "    # and the \"step factor\" used to plot the graph of MSE\n",
    "    # for each method\n",
    "    random_state = 42\n",
    "    n_jobs = 1 # Parallelisation factor for bagging, random forests\n",
    "    n_estimators = 1000\n",
    "    step_factor = 10\n",
    "    axis_step = int(n_estimators/step_factor)\n",
    "    # Download ten years worth of Amazon\n",
    "    # adjusted closing prices\n",
    "    start = datetime.datetime(2006, 1, 1)\n",
    "    end = datetime.datetime(2015, 12, 31)\n",
    "    amzn = create_lagged_series(\"AMZN\", start, end, lags=3)\n",
    "    amzn.dropna(inplace=True)\n",
    "    \n",
    "    # Use the first three daily lags of AMZN closing prices\n",
    "    # and scale the data to lie within -1 and +1 for comparison\n",
    "    X = amzn[[\"Lag1\", \"Lag2\", \"Lag3\"]]\n",
    "    y = amzn[\"Today\"]\n",
    "    X = scale(X)\n",
    "    y = scale(y)\n",
    "    \n",
    "    # Use the training-testing split with 70% of data in the\n",
    "    # training data with the remaining 30% of data in the testing\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.3, random_state=random_state\n",
    "#         )\n",
    "    \n",
    "#     # Pre-create the arrays which will contain the MSE for\n",
    "#     # each particular ensemble method\n",
    "#     estimators = np.zeros(axis_step)\n",
    "#     bagging_mse = np.zeros(axis_step)\n",
    "#     rf_mse = np.zeros(axis_step)\n",
    "#     boosting_mse = np.zeros(axis_step)\n",
    "    # Estimate the Bagging MSE over the full number\n",
    "    # of estimators, across a step size (\"step_factor\")\n",
    "#     for i in range(0, axis_step):\n",
    "#         print(\"Bagging Estimator: %d of %d...\" % (\n",
    "#             step_factor*(i+1), n_estimators)\n",
    "#             )\n",
    "        \n",
    "#         bagging = BaggingRegressor(DecisionTreeRegressor(), n_estimators=step_factor*(i+1), n_jobs=n_jobs,\n",
    "#                                random_state=random_state)\n",
    "    \n",
    "#         bagging.fit(X_train, y_train)\n",
    "        \n",
    "#         mse = mean_squared_error(y_test, bagging.predict(X_test))\n",
    "#         estimators[i] = step_factor*(i+1)\n",
    "#         bagging_mse[i] = mse\n",
    "    \n",
    "    # Estimate the Random Forest MSE over the full number\n",
    "    # of estimators, across a step size (\"step_factor\")\n",
    "    \n",
    "#     for i in range(0, axis_step):\n",
    "#         print(\"Random Forest Estimator: %d of %d...\" % (step_factor*(i+1), n_estimators))\n",
    "        \n",
    "#         rf = RandomForestRegressor(\n",
    "#             n_estimators=step_factor*(i+1),\n",
    "#             n_jobs=n_jobs,\n",
    "#             random_state=random_state\n",
    "#             )\n",
    "#         rf.fit(X_train, y_train)\n",
    "#         mse = mean_squared_error(y_test, rf.predict(X_test))\n",
    "#         estimators[i] = step_factor*(i+1)\n",
    "#         rf_mse[i] = mse\n",
    "        \n",
    "        # Estimate the AdaBoost MSE over the full number\n",
    "        # of estimators, across a step size (\"step_factor\")\n",
    "    \n",
    "#     for i in range(0, axis_step):\n",
    "#         print(\"Boosting Estimator: %d of %d...\" % (\n",
    "#         step_factor*(i+1), n_estimators)\n",
    "#         )\n",
    "            \n",
    "#         boosting = AdaBoostRegressor(\n",
    "#             DecisionTreeRegressor(),\n",
    "#             n_estimators=step_factor*(i+1),\n",
    "#             random_state=random_state,\n",
    "#             learning_rate=0.01\n",
    "#             )\n",
    "        \n",
    "#         boosting.fit(X_train, y_train)\n",
    "#         mse = mean_squared_error(y_test, boosting.predict(X_test))\n",
    "#         estimators[i] = step_factor*(i+1)\n",
    "#         boosting_mse[i] = mse\n",
    "    \n",
    "    \n",
    "    # Plot the chart of MSE versus number of estimators\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.title(’Bagging, Random Forest and Boosting comparison’)\n",
    "#     plt.plot(estimators, bagging_mse, ’b-’, color=\"black\", label=’Bagging’)\n",
    "#     plt.plot(estimators, rf_mse, ’b-’, color=\"blue\", label=’Random Forest’)\n",
    "#     plt.plot(estimators, boosting_mse, ’b-’, color=\"red\", label=’AdaBoost’)\n",
    "#     plt.legend(loc=’upper right’)\n",
    "#     plt.xlabel(’Estimators’)\n",
    "#     plt.ylabel(’Mean Squared Error’)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our data\n",
    "df_features=pd.read_csv('prices.csv')\n",
    "\n",
    "df_features['date'] = pd.to_datetime(df_features['date'])\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = df_features.loc[df_features.loc[:,'Ticker'] == 'AAL', ['date', 'close']]\n",
    "a.plot(x = 'date', y = 'close')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\meenm\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.940000</td>\n",
       "      <td>9837300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAP</td>\n",
       "      <td>40.700001</td>\n",
       "      <td>40.360001</td>\n",
       "      <td>41.040001</td>\n",
       "      <td>1701700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>30.490000</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.642857</td>\n",
       "      <td>123432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC</td>\n",
       "      <td>26.290001</td>\n",
       "      <td>26.139999</td>\n",
       "      <td>26.690001</td>\n",
       "      <td>2455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABT</td>\n",
       "      <td>26.000339</td>\n",
       "      <td>25.870792</td>\n",
       "      <td>26.177866</td>\n",
       "      <td>10829000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker       open        low       high     volume\n",
       "0    AAL   4.840000   4.660000   4.940000    9837300\n",
       "1    AAP  40.700001  40.360001  41.040001    1701700\n",
       "2   AAPL  30.490000  30.340000  30.642857  123432400\n",
       "3    ABC  26.290001  26.139999  26.690001    2455900\n",
       "4    ABT  26.000339  25.870792  26.177866   10829000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train = df_features.loc[(df_features['date'] < '2016-01-01'),:]\n",
    "y_train = X_train['close']\n",
    "X_train.drop(['close', 'date'], axis = 1, inplace = True)\n",
    "\n",
    "X_test = df_features.loc[(df_features['date'] > '2015-12-31'), :]\n",
    "y_test = X_test['close']\n",
    "X_test.drop(['close', 'date'], axis = 1, inplace = True)\n",
    "\n",
    "#X_train.head()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\meenm\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_one = X_train.loc[X_train['Ticker'] == 'AAPL', :]\n",
    "y_train_one = y_train[X_train_one.index]\n",
    "\n",
    "X_test_one = X_test.loc[X_test['Ticker'] == 'AAPL', :]\n",
    "y_test_one = y_test[X_test_one.index]\n",
    "\n",
    "X_train_one.drop(['Ticker'], axis = 1, inplace = True)\n",
    "X_test_one.drop(['Ticker'], axis = 1, inplace = True)\n",
    "\n",
    "mod = RandomForestRegressor()\n",
    "mod.fit(X_train_one, y_train_one)\n",
    "#mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6366600208803723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = mod.predict(X_test_one)\n",
    "y_test_one_df = pd.DataFrame(y_test_one)\n",
    "print(mean_squared_error(y_test_one, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.94699940000001\n",
      "105.349998\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[0])\n",
    "print(y_test_one.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
